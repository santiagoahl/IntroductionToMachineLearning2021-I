{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "entregable_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyDuPdyOG5TBdV0QM7+HH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagoahl/ml_/blob/main/entregable_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_0e59a0T_yo"
      },
      "source": [
        "Entregable n√∫mero 1 - Santiago Ahumada Lozano\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvtAAQnNVMZo"
      },
      "source": [
        "# Exercise 1.2\n",
        "We begun thinking the messages as the frecuency of occurrence of the keywords whose the perceptron will work with,  then our unknown target fuction will look like:\n",
        "\n",
        "$$\n",
        "f:X\\rightarrow Y\n",
        "$$\n",
        "Where,\n",
        "\\begin{align*}\n",
        "&f(x)=+1, \\text{if the message $x$ is considered spam} \\\\\n",
        "&f(x)=-1, \\text{if not}\n",
        "\\end{align*}\n",
        "\n",
        "a) We tought of some keywords that will end up with large positive weights in the perceptron and we found this examples:\n",
        "\n",
        "\n",
        "1.   Take advantage\n",
        "2.   Right know\n",
        "3.Unique\n",
        "4. For sale\n",
        "5. Unforgettable\n",
        "\n",
        "b)We tought about inputs that will end up in negative values of $Y$ and we found the following examples:\n",
        "\n",
        "\n",
        "1.   Invitation\n",
        "2.   Security alert\n",
        "3. Reminder: ...\n",
        "4.Recommended \n",
        "5.Pay \n",
        "\n",
        "c)The parameter of the vector $x$ in the perceptron model which directly make the target function decide to clasify as spam is the number of keywords considered as spam i.e. its associated weights. \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDW8vqAz-0Rs"
      },
      "source": [
        "# Exercise 1.3\n",
        "\n",
        "Remmember that we want to find the correct vector of weights $$\\mathbf{w}=(w_{1},...,w_{n})$$ \n",
        "By using the formula \n",
        "$$\\mathbf{w}(t+1)=\\mathbf{w}(t)+y(t)\\mathbf{x}(t)$$\n",
        "\n",
        "a)Now we want to show that $ \\mathbf{y}(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) < 0 $ . In fact, since $x(t)$ is missclasified by $\\mathbf{w}(t)$, then $y(t)\\neq sign(\\mathbf{w}^{T}(t)\\mathbf{x}(t))$ and therefore its product must be negative.\n",
        "\n",
        "b)Also we have $y(t)\\mathbf{w}^{T}(t+1)\\mathbf{x}(t) > y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)$, \n",
        "\n",
        "\\begin{align*}\n",
        "y(t) \\mathbf{w}^{T}(t+1) \\mathbf{x}(t) &= y(t)( \\mathbf{w}^{T}(t)+y(t)\\mathbf{x}^{T}(t))\\mathbf{x}(t) \\\\\n",
        " &= y(t)(( \\mathbf{w}^{T}(t)\\mathbf{x}(t)+y(t)\\mathbf{x}^{T}(t)\\mathbf{x}(t)) \\\\\n",
        " &=y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) + y^{2}(t)\\mathbf{x}^{T}(t)\\mathbf{x}(t) \\\\\n",
        " &= y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) +  y^{2}(t)\\sum_{i=1}^{N}x_i^{2} \\\\\n",
        " &> y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)\n",
        "\\end{align*} \n",
        "\n",
        "c)We've observed that each term  $y(t)\\mathbf{w}^{T}(t+1)\\mathbf{x}(t)>y(t) \\mathbf{w}^{T}(t)\\mathbf{x}(t)$, then there must be some value of $t$ such that $ y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) > 0 $ i.e. our $\\mathbf{x}$ will end up correctly clasified by $\\mathbf{w}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmnjkOQ5viB5"
      },
      "source": [
        "# Exercise 1.10\n",
        "\n",
        "Here is an experiment that ilustrates the difference between a single bin and multiple bins. Run a computer simulation for flipping 1000 fair coins. Flip each independly 10 times. Let's focus on 3 coins as follows: $c_1$ is the first coin flipped, $c_{rand}$ is a coin picked at random and $c_{min}$ is the coin that had the minimum frequency of heads. Let $\\nu_{1}, \\nu_{rand}, \\nu_{min}$ the fraction of heads you obtain for the respective three coins.\n",
        "\n",
        "# Solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwsBOaJn8soK",
        "outputId": "f5219708-31ea-4f2f-f13a-9fa24507c477"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "nExperiments = 100\n",
        "sum_mu = 0\n",
        "sum_nu_1 = 0\n",
        "sum_nu_rand = 0 \n",
        "sum_C_min = 0\n",
        "\n",
        "for e in range(nExperiments):\n",
        "  nCoins = 1000\n",
        "\n",
        "  val_1=0\n",
        "  val_rand = random.choice(range(1,1000))\n",
        "  val_min = 0\n",
        "  #print('val_rand=',val_rand)\n",
        "\n",
        "  C_1 = 0\n",
        "  C_rand = 0\n",
        "  C_min = 10\n",
        "\n",
        "  #print(C_rand)\n",
        "\n",
        "  nTrials = 1000\n",
        "\n",
        "  for i in range(nTrials):\n",
        "    #print('coin #',i+1)\n",
        "    #Toss a fair coin 10 times\n",
        "    sampleBin = np.random.binomial(1,0.5,10)\n",
        "    nSuccess = np.sum(sampleBin)\n",
        "    if i == val_rand:\n",
        "      C_rand = nSuccess\n",
        "    if i == val_1 : \n",
        "      C_1 = nSuccess\n",
        "    if nSuccess < C_min :\n",
        "      C_min = nSuccess\n",
        "      val_min = i+1\n",
        "      #print(val_min)\n",
        "  #print('Number of heads of this coin',i+1,' ', nSuccess, 'Minimum_heads= ', C_min)\n",
        "\n",
        "    nu_1 = C_1/10\n",
        "    nu_rand = C_rand/10\n",
        "\n",
        "    mu_exp_act = (nu_1+nu_rand+nu_min)/3\n",
        "\n",
        "    #print('\\n The average value of those 3 means (In the actual experiment) is',mu_exp_act)\n",
        "    \n",
        "  sum_nu_1 += nu_1\n",
        "  sum_nu_rand += nu_rand \n",
        "  sum_C_min += C_min\n",
        "  sum_mu += mu_exp_act\n",
        "\n",
        "nu_1 = sum_nu_1/nExperiments\n",
        "nu_rand = sum_nu_rand/nExperiments\n",
        "C_min = int(sum_C_min/nExperiments)\n",
        "mu = sum_mu/nExperiments\n",
        "\n",
        "print('Probability of getting 10 heads if you toast the first fair coin 10 times:', nu_1)\n",
        "print('Probability of getting 10 heads if you toast a random fair coin 10 times:', nu_rand)\n",
        "print('The expected minimum number of heads is:', C_min)\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of getting 10 heads if you toast the first fair coin 10 times: 0.494\n",
            "Probability of getting 10 heads if you toast a random fair coin 10 times: 0.467\n",
            "The expected minimum number of heads is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-i_nyAscnyZ"
      },
      "source": [
        "The probability found of getting 10 heads if you toast the first fair coin 10 times: 0.49\n",
        "Probability of getting 10 heads if you toast a random fair coin 10 times: 0.46\n",
        "The expected minimum number of heads is: 0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSm6CZAdL6E"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    }
  ]
}